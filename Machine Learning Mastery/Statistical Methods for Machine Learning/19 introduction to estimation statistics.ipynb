{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Chapter 19\n",
    "# Introduction to Estimation Statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Statistical hypothesis tests can be used to indicate whether the difference between two samples is due to random chance, but cannot comment on the size of the difference.  A group of methods referred to as 'estimation statistics' are seeing increased use instead of, or in addition to, p-values, in order to quantify the magnitude of effects and the amount of uncertainty for estimated values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Problems with Hypothesis Testing\n",
    "Statistical hypothesis testing and the calculation of p-values can be used to describe whether or not two samples have the same distribution, and to interpret whether the difference between sample means is real or due to random chance.  However:\n",
    "- calculated p-values are easily misused and misunderstood\n",
    "- there's always some significant difference between samples, even if the difference is tiny\n",
    "\n",
    "In the 1990s, the Journal of Epidemiology banned the use of p-values.  Many related areas in medicine and psychology have followed suit.  Although p-values may still be used, there is a push towards the presentation of results using estimation statistics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Estimation Statistics\n",
    "Estimation statistics refers to methods that attempt to quantify a finding.  This might include quantifying the size of an effect, or the amount of uncertainty for a specific outcome or result.\n",
    "\n",
    "The three main classes of methods include:\n",
    "- Effect Size - methods for quantifying the size of an effect given a treatmnent or intervention\n",
    "- Interval Estimation - methods for quantifying the amount of uncertainty in a value\n",
    "- Meta-Analysis - methods for quantifying the findings across multiple similar studies\n",
    "\n",
    "The main reason for the shift from statistical hypothesis methods to estimation systems is that the results are easier to analyse and interpret in the context of the domain or research question.  The quantified size of the effect and uncertainty allows claims to be made that are easier to understand and use.  The results are more meaningful."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Effect Size\n",
    "The effect size describes the magnitude of a treatment or difference between two samples (see also chapter 14).\n",
    "\n",
    "A hypothesis test can comment on whether the difference between samples is the result of chance or is real, whereas an effect size puts a number on how much the samples differ.  \n",
    "\n",
    "There are two main classes of technique used to quantify the magnitude of effects:\n",
    "- Association - the degree to which two samples change together e.g. calculations of correlation, such as the Pearson's correlation coefficient, and the r-squared coefficient of determination.  They may quantify the linear or monotonic way that observations in two samples change together.\n",
    "- Difference - the degree to which two samples are different e.g. Cohen's d statistic, which provides a standardised measure for how the means of two populations differ."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Interval Estimation\n",
    "This refers to statistical methods for quantifying the uncertainty for an observation.  Intervals transform a point estimate into a range that provides more information about the estimate, such as its precision, making them easier to compare and interpret.\n",
    "\n",
    "The three main types of intervals that are commonly calculated are:\n",
    "- Tolerance Interval - the bounds or coverage of a proportion of a distribution with a specific level of confidence.  This may be used to set expectations on observations in a population, or help to identify outliers.\n",
    "- Confidence Interval - the bounds on the estimate of a population parameter.  This can be used to interpret the range for a mean of a data sample that can become more precise as the sample size is increased.\n",
    "- Prediction Interval - the bounds on a single observation.  This can be used to provide a range for a prediction or forecast from a model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Meta-Analysis\n",
    "This refers to the use of a weighting of multiple similar studies in order to quantify a broader cross-study effect.  Meta studies are useful when many small and similar studies have been performed with noisy and conflicting findings.  Instead of taking the study conclusions at face value, statistical methods are used to combine multiple findings into a stronger finding than any single study.\n",
    "\n",
    "Although not often used in applied machine learning, it is useful to note meta-analyses as they form part of the new statistical methods."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}