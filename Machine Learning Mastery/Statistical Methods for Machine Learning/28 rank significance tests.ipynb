{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a6d5379567e5c9aa2d153209ef4a1d00a383d1ae7f32ebada2471f125a521807"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Chapter 28\n",
    "# Rank Significance Tests"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In applied machine learning, we often need to determine whether two data samples have the same or different distributions.  If the data does not have the familiar Gaussian distribution, we must resort to nonparametric versions of the significance tests.  These tests operate in a similar manner, but are distribution free, requiring that real valued data be first transformed into rank data before the test can be performed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Nonparametric Statistical Significance Tests\n",
    "Nonparametric statistical methods were developed for use with ordinal or interval data, but in practice can also be used with a ranking of real-valued observations in a data sample, rather than on the observation values themselves.\n",
    "\n",
    "A common question about two or more datasets is whether they are different: specifically, whether the difference between their central tendency (e.g. mean or median) is statistically significant.\n",
    "\n",
    "The null hypothesis of nonparametric statistical significance tests is often the assumption that both samples were drawn from a population with the same distribution, and therefore have the same population parameters (such as mean or median).\n",
    "\n",
    "These tests are often used on samples of model skill scores in order to confirm that the difference in skill between machine learning models is significant.\n",
    "\n",
    "In general, each test calculates a test statistic, that must be interpreted with some background in statistics and a deeper knowledge of the statistical test itself.  Tests also return a p-value that can be used to interpret the result of the test: it can be thought of as the probability of observing the two data samples given the null hypothesis that the two samples were drawn from a population with the same distribution.  The p-value can be interpreted in the context of a chosen significance level called alpha (commonly 5% or 0.05):\n",
    "- p-value <= alpha: sigificant result, so reject null hypotheses i.e. samples were likely drawn from populations with differing distributions\n",
    "- p-value > alpha: non-significant result, so fail to reject null hypothesis i.e. samples were likely drawn from the same distribution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Test Dataset\n",
    "We will generate two samples drawn from different distributions:\n",
    "- one sample of 100 uniform random numbers between 50-59\n",
    "- one sample of 100 uniform random numbers between 51-60\n",
    "\n",
    "We expect the statistical tests to discover that the samples were drawn from differing distributions, although the small sample size will add some noise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data1: min=50.001 max=59.889\ndata2: min=51.126 max=60.973\n"
     ]
    }
   ],
   "source": [
    "# generate data samples\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two sets of univariate observations\n",
    "data1 = 50 + (rand(100) * 10)\n",
    "data2 = 51 + (rand(100) * 10)\n",
    "\n",
    "# summarize\n",
    "print('data1: min=%.3f max=%.3f' % (min(data1), max(data1)))\n",
    "print('data2: min=%.3f max=%.3f' % (min(data2), max(data2)))"
   ]
  },
  {
   "source": [
    "# Mann-Whitney U Test\n",
    "This is a nonparametric statistical significance test for determing whether two independent samples were drawn from a population with the same distribution.\n",
    "\n",
    "The null hypothesis is that there is no difference between the distributions of the data samples.  Rejection of this hypothesis suggests that there is likely some difference between the samples.\n",
    "\n",
    "More specifically, the test determines whether it is equally likely that any randomly selected observation from one sample will be greater or less than a sample in the other distribution.  If violated, it suggests differing distributions\n",
    "- fail to reject H0 - sample distributions are equal\n",
    "- reject H0 - sample distributions are not equal\n",
    "\n",
    "For the test to be effective, it requires at least 20 observations in each data sample.\n",
    "\n",
    "We can implement the Mann-Whitney U test using the SciPy function mannwhitneyu(), which takes the two data samples as arguments, and returns the test statistic and p-value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=4077.000, p=0.012\nDifferent distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# example of the mann-whitney u test\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two independent samples\n",
    "data1 = 50 + (rand(100) * 10)\n",
    "data2 = 51 + (rand(100) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "\n",
    "# the p-value of 0.012 strongly suggests the sample distributions are different"
   ]
  },
  {
   "source": [
    "# Wilcoxon Signed-Rank Test\n",
    "In some cases, the data samples may be paired e.g. the samples\n",
    "- are related or matched in some way\n",
    "- represent two measurements of the same technique\n",
    "- are independent samples from the same population\n",
    "\n",
    "Examples of paired samples in machine learning might be:\n",
    "- the same algorithm evaluated on different datasets\n",
    "- different algorithms evaluated on exactly the same training and test data\n",
    "\n",
    "The samples are not independent, and therefore the Mann-Whitney U test cannot be used.  Instead, the Wilcoxon t-test is used.  This is the equivalent of the paired Student's t-test, but for ranked data instead of real valued data with a Gaussian distribution.\n",
    "\n",
    "The null hypothesis is that the two samples have the same distribution:\n",
    "- fail to reject H0 - the sample distributions are equal\n",
    "- reject H0 - the sample distributions are not equal\n",
    "\n",
    "For the test to be effective, it requires at least 20 observations in each data sample.\n",
    "\n",
    "The test can be implemented using the SciPy function wilcoxon(), which takes the two samples as arguments, and returns the calculated statistic and p-value.\n",
    "\n",
    "In our example, the two samples are technically not paired, but we can pretend they are for the sake of demonstrating the calculation of this significance test."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=1937.000, p=0.043\nDifferent distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# example of the wilcoxon signed-rank test\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two independent samples\n",
    "data1 = 50 + (rand(100) * 10)\n",
    "data2 = 51 + (rand(100) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "\n",
    "# the p-value of 0.043 strongly suggests that the samples are drawn from different distributions"
   ]
  },
  {
   "source": [
    "# Kruskal-Wallis H Test\n",
    "When working with significance tests (such as Mann-Whitney U and Wicoxon signed-rank), comparisons between data samples must be performed pairwise.  This can be inefficient if you have many data samples and are only interested in whether two or more samples have a different distribution.\n",
    "\n",
    "The Kruskal-Wallis test is a nonparametric version of the one-way analysis of variance (ANOVA) test, and can be used to determine whether more than two independent samples have a different distribution.  It can be thought of as a generalisation of the Mann-Whitney U test.\n",
    "\n",
    "The null hypothesis is that all data samples werwe drawn from the same distribution: specifically, that the population medians of all groups are equal.\n",
    "\n",
    "A rejection of the null hypothesis indicates that there is enough evidence to suggest that one or more samples dominate another sample, but the test does not indicate which samples or by how much\n",
    "- fail to reject H0 - all sample distributions are equal\n",
    "- reject H0 - one or more sample distributions are not equal\n",
    "\n",
    "Each data sample must be independent and have 5 or more observations.  The data samples can differ in size."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=34.747, p=0.000\nDifferent distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# example of the kruskal-wallis h-test\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate three independent samples, each with a slightly different sample mean\n",
    "data1 = 50 + (rand(100) * 10)\n",
    "data2 = 51 + (rand(100) * 10)\n",
    "data3 = 52 + (rand(100) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = kruskal(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n",
    "\n",
    "# the p-value of 0.00 correctly suggests that we reject the null hypothesis"
   ]
  },
  {
   "source": [
    "# Friedman Test\n",
    "As in the previous example, we may have more than two different samples and an interest in whether all samples have the same distribution.  If the samples are paired in some way (such as repeated measures) then the Kruskal-Wallis H test would not be appropriate.\n",
    "\n",
    "Instead the Friedman test can be used: this is the nonparametric version of the repeated measures analysis of variance test, or repeated measures ANOVA.  The test can be thought of as a generalisation of the Kruskal-Wallis H Test to more than two samples.\n",
    "\n",
    "The null hypothesis is that the multiple paired samples have the same distribution:\n",
    "- fail to reject H0 - paired sample distributions are equal\n",
    "- reject H0 - paired sample distributions are not equal\n",
    "\n",
    "The test assumes two or more paired data samples with 10 or more samples per group\n",
    "\n",
    "The test can be implemented using the SciPy function friedmanchisquare(), which takes as arguments the data samples to compare, and returns the calculated statistic and p-value.\n",
    "\n",
    "In our example, the samples are technically not paired, but we can pretend they are for the sake of demonstrating the calculation of this significance test."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=36.240, p=0.000\nDifferent distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# example of the friedman test\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate three independent samples\n",
    "data1 = 50 + (rand(100) * 10)\n",
    "data2 = 51 + (rand(100) * 10)\n",
    "data3 = 52 + (rand(100) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = friedmanchisquare(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n",
    "\n",
    "# the p-value of 0.00 correctly suggests that we reject the null hypothesis"
   ]
  },
  {
   "source": [
    "# Extensions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=482249.000, p=0.085\nSame distribution (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# update the mann-whitney u test example to operate on data samples that have the same distribution\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two independent samples\n",
    "data1 = 50 + (rand(1000) * 10)\n",
    "data2 = 50 + (rand(1000) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "\n",
    "# the p-value of 0.085 suggests the sample distributions are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=238750.000, p=0.208\nSame distribution (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# update the wilcoxon signed-rank test example to operate on data samples that have the same distribution\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two independent samples\n",
    "data1 = 50 + (rand(1000) * 10)\n",
    "data2 = 50 + (rand(1000) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distribution (reject H0)')\n",
    "\n",
    "# the p-value of 0.208 strongly suggests that the samples are drawn from the same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=3.343, p=0.188\nSame distributions (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# update the kruskal-wallis h-test example to operate on data samples that have the same distribution\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate three independent samples, each with the same sample mean\n",
    "data1 = 50 + (rand(100) * 10)\n",
    "data2 = 50 + (rand(100) * 10)\n",
    "data3 = 50 + (rand(100) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = kruskal(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n",
    "\n",
    "# the p-value of 0.188 with a sample size of 100 correctly suggests that we fail to reject the null hypothesis\n",
    "# however the p-value of 0.018 with sample sizes of 1000 suggests that the distributions are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=6.714, p=0.035\nDifferent distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# update the friedman test example to operate on data samples that have the same distribution\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate three independent samples\n",
    "data1 = 50 + (rand(100) * 10)\n",
    "data2 = 50 + (rand(100) * 10)\n",
    "data3 = 50 + (rand(100) * 10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = friedmanchisquare(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n",
    "\n",
    "# the p-value of 0.054 with a sample size of 100 correctly suggests that we reject the null hypothesis\n",
    "# however the p-value of 0.035 with a sample size of 1000 suggests that the distributions are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}