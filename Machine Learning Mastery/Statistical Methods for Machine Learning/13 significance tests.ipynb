{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Chapter 13\n",
    "# Significance Tests"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Parametric statistical tests assume that a data sample was drawn from a specific population distribution.\n",
    "\n",
    "A typical question we may have about 2 or more samples of data is whether they have the same distribution.\n",
    "\n",
    "Parametric statistical significance tests are those statistical methods that assume data comes from the same Gaussian distribution i.e. with the same mean and standard deviation.\n",
    "\n",
    "In general, each test calculates a test statistic that must be interpreted with some background in statistics and a deeper knowledge of the statistical test itself.\n",
    "\n",
    "Tests also return a p-value: the probability of observing the two data samples given the null hypothesis that the two samples were drawn from a population with the same distribution.\n",
    "\n",
    "The p-value can be interpreted in the context of a chosen significance level (alpha), commonly 5% or 0.05:\n",
    "- p-value <= alpha - significant result, so reject null hypothesis i.e. distributions differe\n",
    "- p-value > alpha - non-significant result, so fail to reject null hypothesis i.e. distributions same"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Test Data\n",
    "Define a test dataset we can use to demonstrate each test.\n",
    "\n",
    "Generate two samples from different Gaussian distributions:\n",
    "- the first is scaled to have a mean of 50 and standard deviation of 5\n",
    "- the second is scaled to have a mean of 51 and a standard deviation of 5\n",
    "\n",
    "We are using a small sample size of 100 observations per sample, which add some noise to the decision of whether or not the samples have been drawn from differing distributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data1: mean=50.303 stdv=4.426\ndata2: mean=51.764 stdv=4.660\n"
     ]
    }
   ],
   "source": [
    "# generate gaussian data samples\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two sets of univariate observations\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "\n",
    "# summarize\n",
    "print('data1: mean=%.3f stdv=%.3f' % (mean(data1), std(data1)))\n",
    "print('data2: mean=%.3f stdv=%.3f' % (mean(data2), std(data2)))"
   ]
  },
  {
   "source": [
    "# Student's t-Test\n",
    "This is a statistical hypothesis test that 2 independent data samples, known to have a Gaussian distribution, have the same Gaussian distribution\n",
    "\n",
    "Null hypothesis (H0) is that the means of the two populations are equal.  A rejection of the hypothesis indicates there is sufficient evidence that the means are different, and therefore the distbutions are not equal\n",
    "\n",
    "The t-Test is available via the SciPy function ttest_ind(), which accepts two data samples as arguments, and returns the calculated statistic and p-value.\n",
    "\n",
    "The test assumes both samples have the same variance.  If this is not the case, a corrected version of the test can be used by setting equal_var = False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=-2.262, p=0.025\nDifferent distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# student's t-test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two independent samples as above\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "\n",
    "# compare samples\n",
    "stat, p = ttest_ind(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret using a 5% signficance level\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "source": [
    "# Paired Student's t-Test\n",
    "We may wish to compare the means between two data samples that are related in some way e.g. two independent measures or evaluations of the same object\n",
    "\n",
    "Because the samples are not inependent, we cannot use the Student's t-test.  Instead, we must use a modified version of the test that corrects for the fact that the samples are dependent, called the paired Student's t-test.\n",
    "\n",
    "The null hypothesis is that there is no difference in the means between the samples.  The rejection of the null hypothesis indicates that there is enough evidence that the sample means are different:\n",
    "- fail to reject H0 - paired sample distributions are equal\n",
    "- reject H0 - paired sample distributions are not equal\n",
    "\n",
    "The paired Student's t-test is available via the SciPy function ttest_rel(), which accepts two data samples as arguments, and returns the calculated statistic and p-value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=-2.372, p=0.020\nDifferent distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# paired student's t-test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate two independent samples, as before.  Although the samples are independent, not paired, we can pretend for the sake of the demonstration that the observations are paired and calculate the statistic\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "\n",
    "# compare samples\n",
    "stat, p = ttest_rel(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret using a 5% significance level   \n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "source": [
    "# Analysis of Variance Test (ANOVA)\n",
    "There are sometimes situations where we may have multiple independent data samples.  We can perform the Student's t-test pairwise on each combination of the data samples to get an idea of which samples have different means.  This can be onerous if we are only interested in whether or not all samples have the same distribution: so we can use the Analysis of Variance test (ANOVA)\n",
    "\n",
    "ANOVA is a statistical test that assumes that the mean across 2 or more groups are equal:\n",
    "- fail to reject H0 - all sample distributions are equal\n",
    "- reject H0 - one or more sample distributions are not equal\n",
    "\n",
    "Importantly, the test can only comment on whether or not all samples are the same: it cannot quantify which samples differ, or by how much\n",
    "\n",
    "The test requires that:\n",
    "- the data samples are a Gaussian distribution\n",
    "- the samples are independent\n",
    "- all data samples have the same standard deviation\n",
    "\n",
    "The ANOVA test is available via the SciPy function f_oneway(), which takes two or more data samples as arguments and returns the test statistic and f-value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=3.655, p=0.027\nDifferent distributions (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# analysis of variance test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "\n",
    "# generate three independent samples - two the same and one different\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "\n",
    "# compare samples\n",
    "stat, p = f_oneway(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret using a 5% significance level\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "source": [
    "# Repeated Measures ANOVA Test\n",
    "We may have multiple data samples that are related or dependent in some way e.g. repeating the same measurements on a subject at different time periods\n",
    "\n",
    "As we will have multiple paired samples, we could repeat the pairwise Student's t-test multiple times\n",
    "\n",
    "Alternatively, we can use a single test to check if all of the samples have the same mean, called the repeated measures ANOVA test\n",
    "\n",
    "The null hypothesis is that all paired samples have the same mean, and therefore the same distribution:\n",
    "- fail to reject H0 - all paired sample distributions are equal\n",
    "- reject H0 - one or more paired sample distributions are not equal\n",
    "\n",
    "Unfortunately, at the time of writing, there is no version of the repeated measures ANOVA test available in SciPy."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Extensions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=-0.415, p=0.679\nSame distributions (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# update student's t-test example to operate on data samples with the same distribution\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# generate two independent samples as above\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "\n",
    "# compare samples\n",
    "stat, p = ttest_ind(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret using a 5% signficance level\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=0.290, p=0.772\nSame distributions (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# update paired student's t-test example to operate on data samples with the same distribution\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# generate two independent samples, as before.  Although the samples are independent, not paired, we can pretend for the sake of the demonstration that the observations are paired and calculate the statistic\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "\n",
    "# compare samples\n",
    "stat, p = ttest_rel(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret using a 5% significance level   \n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Statistics=0.166, p=0.847\nSame distributions (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# update analysis of variance test example to operate on data samples with the same distribution\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# generate three independent samples - two the same and one different\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 50\n",
    "\n",
    "# compare samples\n",
    "stat, p = f_oneway(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret using a 5% significance level\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}