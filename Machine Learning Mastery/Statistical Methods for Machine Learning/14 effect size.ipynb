{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Chapter 14\n",
    "# Effect Size"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Statistical hypothesis tests report on the likelihood of the observed results given an assumption (such as no association between variables, or no difference between groups)\n",
    "\n",
    "Hypothesis tests do not comment on the size of the effect if the association or difference is statistically significant.  The results of an experiement could be significant, but the effect so small that it has little consequence.\n",
    "\n",
    "Effect size methods refer to a suite of statistical tools for quantifying the size of an effect in the results of experiments, that can be used to complement the results from statistical hypothesis tests."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "An effect size refers to the size or magnitude of an effect or result as it would be expected to occur in a population.  The effect size is estimated from samples of data.\n",
    "\n",
    "An effect can be the result of a treatment revealed in a comparison between groups (e.g. treated and untreated groups), or can describe the degree of assocaition between two related variables (e.g. treatment dosage and health)\n",
    "\n",
    "Effect size methods refers to a collection of statistical tools used to calculate the effect size.  It is common to organise the methods into groups, based on the type of affect to be quantified.  Two main groups of methods for calculating effect size are:\n",
    "- Association - statistical methods for quantifying an assocation between variables (e.g. correlation)\n",
    "- Difference - statistical methods for quantifying the difference between variables (e.g. difference between means)\n",
    "\n",
    "The result of an effect size calculation must be interpreted.  A measure must be chosen based on the goals of the interpretation.  Three types of calculated result include:\n",
    "- Standardised Result - the effect size has a standard scale allowing it to be interpreted generally regardless of application (e.g. Cohen's d calculation)\n",
    "- Original Units Result - the effect size may use the original units of the variable, which can aid in the interpretation within the domain (e.g. difference between two sample means)\n",
    "- Unit Free Result - the effect size may not have units, such as a count or proportion (e.g. a correlation coefficient)\n",
    "\n",
    "It may be a good idea to report an effect size using multiple measures, to aid the different types of readers of your findings\n",
    "\n",
    "The effect size does not replace the results of the statistical hypothesis test: it complements them:\n",
    "- Hypothesis Test - quantify the likelihood of observing the data given an assumption (null hypothesis)\n",
    "- Effect Size - quantify the size of the effect assuming that the effect is present"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Calculate Association Effect Size\n",
    "The association between variables is often referred to as the r family of effect size methods.\n",
    "\n",
    "The Pearson's correlation coefficient (aka Pearson's r) measures the degree of linear association between two real-valued variables.\n",
    "\n",
    "It is a unit-free effect size measure, that can be interpreted in a standard way:\n",
    "- -1.0 = perfect negative relationship\n",
    "- -0.7 = strong negative relationship\n",
    "- -0.5 = moderate negative relationship\n",
    "- -0.3 = weak negative relationship\n",
    "- 0.0 = no relationship\n",
    "- 0.3 = weak positive relationship\n",
    "- 0.5 = moderate positive relationship\n",
    "- 0.7 = strong positive relationship\n",
    "- 1.0 = perfect positive relationship\n",
    "\n",
    "The Pearson's correlation coefficient can be calculated using the SciPy function pearsonr()\n",
    "\n",
    "Another very popular method for calculating the association effect size is the r-squared measure, also called the coefficient of determination.  It summarises the proportion of variance in one variable explained by the other"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pearsons correlation: 0.712\n"
     ]
    }
   ],
   "source": [
    "# calculate the pearson's correlation between two variables\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# prepare data\n",
    "data1 = 10 * randn(10000) + 50\n",
    "data2 = data1 + (10 * randn(10000) + 50)\n",
    "\n",
    "# calculate pearson's correlation\n",
    "corr, _ = pearsonr(data1, data2)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "source": [
    "# Calculate Difference Effect Size\n",
    "The difference between groups is often referred to as the d family of effect size methods.\n",
    "\n",
    "Cohen's d measures the difference between the mean from two Gaussian-distributed vvariables.  It is a standard score theat summarises the difference in terms of the number of standard deviations:\n",
    "- Small Effect Size: d = 0.20\n",
    "- Medium Effect Size: d = 0.50\n",
    "- Large Effect Size: d = 0.80\n",
    "\n",
    "The Cohen's d calculation is not provivded in Python, but can be calculated manually:\n",
    "- d = ((mean of first sample) - (mean of second sample))/(pooled standard deviation of both samples)\n",
    "\n",
    "See the following example for calculation of the pooled standard deviation\n",
    "\n",
    "Two other popular methods for quantifying the difference effect size are:\n",
    "- Odds Ratio - measures the odds of an outcome occuring from one treatment compared to another\n",
    "- Relative Risk Ratio - measures the probabilities of an outcome occuring from one treatment compared to another"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate Cohen's d for independent samples\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "\n",
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1 = len(d1)\n",
    "    n2 = len(d2)\n",
    "\n",
    "    # calculate the variance of the samples (the degrees of freedom used in the calculation is n - ddof)\n",
    "    s1 = var(d1, ddof=1)\n",
    "    s2 = var(d2, ddof=1)\n",
    "\n",
    "    # calculate the pooled standard deviation (the subtractions are adjustments for the degrees of freedom)\n",
    "    s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "\n",
    "    # calculate the means of the samples\n",
    "    u1 = mean(d1)\n",
    "    u2 = mean(d2)\n",
    "\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cohens d: 0.500\n"
     ]
    }
   ],
   "source": [
    "# calculate the cohen's d between two samples\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# prepare data - the data is contrived such that the means are different by one half standard deviation, and both samples have the same standard deviation\n",
    "data1 = 10 * randn(10000) + 60\n",
    "data2 = 10 * randn(10000) + 55\n",
    "\n",
    "# calculate cohen's d\n",
    "d = cohend(data1, data2)\n",
    "print('Cohens d: %.3f' % d)"
   ]
  },
  {
   "source": [
    "# Extensions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cohens d: 0.500\n"
     ]
    }
   ],
   "source": [
    "# implement a function to calculate the Cohen's d for paired samples, and demonstrate it on a test dataset\n",
    "# Method 1: Cohen's effect size for repeated measures\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "\n",
    "def cohend_paired(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1 = len(d1)\n",
    "    n2 = len(d2)\n",
    "\n",
    "    # calculate the variance of the samples (the degrees of freedom used in the calculation is n - ddof)\n",
    "    var1 = var(d1, ddof=1)\n",
    "    var2 = var(d2, ddof=1)\n",
    "\n",
    "    # calculate the means of the samples\n",
    "    u1 = mean(d1)\n",
    "    u2 = mean(d2)\n",
    "\n",
    "    # to implement Cohen's effect size for repeated measures, we first need to calculate the correlation coefficient\n",
    "    corr, p = pearsonr(d1, d2)\n",
    "\n",
    "    # now calculate the Cohen's effect size\n",
    "    s_z = sqrt(var1 + var2 - (2 * corr * sqrt(var1) * sqrt(var2)))\n",
    "    s_rm = s_z/sqrt(2*(1-corr))\n",
    "    return (u1 - u2) / s_rm\n",
    "\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# prepare data - although the samples are independent, not paired, we can pretend for the sake of the demonstration that the observations are paired \n",
    "data1 = 10 * randn(10000) + 60\n",
    "data2 = 10 * randn(10000) + 55\n",
    "\n",
    "# calculate cohen's d\n",
    "dz = cohend_paired(data1, data2)\n",
    "print('Cohens d: %.3f' % dz)\n",
    "\n",
    "# to use the interpretation table, d = dz * sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cohens d: 0.500\n"
     ]
    }
   ],
   "source": [
    "# implement a function to calculate the Cohen's d for paired samples, and demonstrate it on a test dataset\n",
    "# Method 2: Cohen's d using an average variance\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "\n",
    "def cohend_paired(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1 = len(d1)\n",
    "    n2 = len(d2)\n",
    "\n",
    "    # calculate the variance of the samples (the degrees of freedom used in the calculation is n - ddof)\n",
    "    var1 = var(d1, ddof=1)\n",
    "    var2 = var(d2, ddof=1)\n",
    "\n",
    "    # calculate average standard deviation\n",
    "    s = sqrt((var1 + var2)/2)\n",
    "\n",
    "    # calculate the means of the samples\n",
    "    u1 = mean(d1)\n",
    "    u2 = mean(d2)\n",
    "\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# prepare data - although the samples are independent, not paired, we can pretend for the sake of the demonstration that the observations are paired \n",
    "data1 = 10 * randn(10000) + 60\n",
    "data2 = 10 * randn(10000) + 55\n",
    "\n",
    "# calculate cohen's d\n",
    "d = cohend_paired(data1, data2)\n",
    "print('Cohens d: %.3f' % d)\n",
    "\n",
    "# This method is preferred, since its values can more easily be compared to d for two independent samples i.e. we can determine whether the effect measured in an experiment with paired samples (e.g. pre-treatment vs post-treatment) is higher or lower than the effect measured in an experiment with two independent samples (e.g. separate treatment and control groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cohens d: 0.357\n"
     ]
    }
   ],
   "source": [
    "# implement a function to calculate the Cohen's d for paired samples, and demonstrate it on a test dataset\n",
    "# Here's another version\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "\n",
    "# this assumes both data sets have same length\n",
    "def cohend_paired(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1 = len(d1)\n",
    "    n2 = len(d2)\n",
    "\n",
    "    # calculate the effect size as the mean of the differences divided by the standard deviation of the differences\n",
    "    mean_diff = sum([d1[i] - d2[i] for i in range(n1)])/n1\n",
    "    sum_of_squares = sum([((d1[i] - d2[i]) - mean_diff)**2 for i in range(n1)])\n",
    "    s = sqrt(sum_of_squares / (n1 - 1))\n",
    "    return mean_diff / s\n",
    "\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "\n",
    "# prepare data - although the samples are independent, not paired, we can pretend for the sake of the demonstration that the observations are paired \n",
    "data1 = 10 * randn(10000) + 60\n",
    "data2 = 10 * randn(10000) + 55\n",
    "\n",
    "# calculate cohen's d\n",
    "dz = cohend_paired(data1, data2)\n",
    "print('Cohens d: %.3f' % dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Odds ratio 4.5\nProbability 0.1152385439301579\nNo significant association between gender and political party preference (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# implement and demonstrate another difference effect measure, such as the odds ratio\n",
    "\n",
    "# the odds ratio is used to determine whether there is a significant assocation between two categorical values in a contingency table, and is calculated as (probability of event)/(probability of non-event)\n",
    "\n",
    "# e.g. in a small sample\n",
    "# - females: 8 voted labour and 4 voted conservative\n",
    "# - males: 4 voted labour and 9 voted conservative\n",
    "# Is there a statistically significant association between gender and political party preference\n",
    "# H0 is no significant association i.e. odds ratio = 1\n",
    "import scipy.stats as stats\n",
    "contingency_table = [[8, 4], [4, 9]]\n",
    "oddsratio, p = stats.fisher_exact(contingency_table)\n",
    "print('Odds ratio', oddsratio)\n",
    "print('Probability', p)\n",
    "\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('No significant association between gender and political party preference (fail to reject H0)')\n",
    "else:\n",
    "    print('Signifiant association between gender and political party preference (reject H0)')\n",
    "\n",
    "# long-hand\n",
    "# odds of female voting labour = 8/4 = 2\n",
    "# odds of male voting labour = 4/9 = 0.444\n",
    "# odds ratio = 2 / 0.444 = 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement and demonstrate another difference effect measure, such as the risk ratio\n",
    "\n",
    "# long-hand for above example\n",
    "# risk of female voting labour = 8 / 12 = 0.67\n",
    "# risk of male voting labour = 4 / 13 = 0.31\n",
    "# risk ratio = 0.67 / 0.31 = 2.17"
   ]
  }
 ]
}